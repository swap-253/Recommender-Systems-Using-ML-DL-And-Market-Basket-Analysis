# -*- coding: utf-8 -*-
"""KNN Recommender.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VHhfFmBhYr99SfwSvzM_YrViTQHCp49_
"""

# Commented out IPython magic to ensure Python compatibility.
# Ignore  the warnings
import warnings
warnings.filterwarnings('always')
warnings.filterwarnings('ignore')
import time
# data visualisation and manipulation
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns
 
#configure
# sets matplotlib to inline and displays graphs below the corressponding cell.
# %matplotlib inline  
style.use('fivethirtyeight')
sns.set(style='whitegrid',color_codes=True)

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

# reading users file:
u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']
users = pd.read_csv('u.user', sep='|', names=u_cols,encoding='latin-1')

# reading ratings file:
r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']
ratings = pd.read_csv('u.data', sep='\t', names=r_cols,encoding='latin-1')

# reading items file:
i_cols = ['movie id', 'movie title' ,'release date','video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',
'Animation', 'Children\'s', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',
'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']
items = pd.read_csv('u.item', sep='|', names=i_cols,
encoding='latin-1')

# After loading the dataset, we should look at the content of each file (users, ratings, items).

# Looking at the user file
print("\nUser Data :")
print("shape : ", users.shape)
#print(users.head())

# We have 943 users in the dataset and each user has 5 features, i.e. user_ID, age, sex, occupation and zip_code. Now letâ€™s look at the ratings file.

# Ratings Data
print("\nRatings Data :")
print("shape : ", ratings.shape)
#print(ratings.head())

# We have 100k ratings for different user and movie combinations. Now finally examine the items file.

# Item Data
print("\nItem Data :")
print("shape : ", items.shape)
#print(items.head())

users.head()

ratings.head()

#converting the unix timestamp of ratings to a  date
from datetime import datetime
def time_stamp(k):
  return datetime.fromtimestamp(k).strftime('%d-%m-%Y')
ratings['rating_date'] = ratings['unix_timestamp'].apply(time_stamp)
ratings.head()

print(pd.DatetimeIndex(ratings['rating_date']).year.min())
print(pd.DatetimeIndex(ratings['rating_date']).year.max())

#finding the no of days since the rating is given on movies from a specified date('01-11-1998')
date_format = "%d-%m-%Y"
def sub_dates(a):
  return (datetime.strptime('01-11-1998', date_format)-a).days   
def dat_strp(a):
    return datetime.strptime(a, date_format)
ratings['new_date']=ratings['rating_date'].apply(dat_strp)    
ratings['days_diff']=ratings['new_date'].apply(sub_dates) 
#conversion of no of days to years
ratings['years_diff']=round(ratings['days_diff']/365,2)
ratings.head()

#dropping the below columns 
ratings.drop(['unix_timestamp','new_date'],axis=1,inplace=True)
ratings.head()

ratings['years_diff'].describe()

#for these values select m=0.425 and n=0.25, this idea is based on max and min values of years difference to get weighted difference
m,n=0.425,0.25
ratings['weighted_diff']=m*ratings['years_diff']+n
ratings.head()

#Now I am gonna create new ratings which are time based/temporal
ratings['final_ratings']=round(ratings['rating']/ratings['weighted_diff'],2)
ratings.head()

ratings['final_ratings'].describe()

items.head()

n_users = ratings.user_id.unique().shape[0]
n_items = ratings.movie_id.unique().shape[0]
data_matrix = np.zeros((n_users, n_items))

#basically here I am filling the respective user ids(line[1]) and movies(line[2]) with the value final ratings(line[8])
for line in ratings.itertuples():
    data_matrix[line[1]-1,line[2]-1] = line[8]
data_matrix

"""#A Recommender Model Using KNN"""

#Now I am gotta merge two columns of items dataset to ratings dataset
items_new=items[['movie id', 'movie title']]
items_new.rename(columns={"movie id": "movie_id"},inplace=True)
df=pd.merge(ratings,items_new,on=['movie_id'],how='inner')
df.head()
# items_new.columns

df.isnull().sum()

#getting how many users have rated each of the movies
movie_ratingCount = (df.groupby(by = ['movie title'])['rating'].count().reset_index().rename(columns = {'rating': 'totalRatingCount'})
[['movie title', 'totalRatingCount']])
movie_ratingCount.head()

#merging the rating counts of movies with the original dataframe by title
ratings_with_RatingCounts = df.merge(movie_ratingCount, left_on = 'movie title', right_on = 'movie title', how = 'left')
ratings_with_RatingCounts.head()

print(movie_ratingCount['totalRatingCount'].describe())

#considering movies having atleast 55 views 
popularity_threshold = 55
rating_popular_movie= ratings_with_RatingCounts[ratings_with_RatingCounts['totalRatingCount']>= popularity_threshold]
rating_popular_movie.head()

rating_popular_movie.shape

## Creating a pivot table with rows as movie title and columns as userid filling with values of final ratings 
movie_features_df=rating_popular_movie.pivot_table(index='movie title',columns='user_id',values='final_ratings').fillna(0)
movie_features_df.head()

#converting movie_features_df to csr format sparse matrices making efficient operations
from scipy.sparse import csr_matrix
movie_features_df_matrix = csr_matrix(movie_features_df.values)
from sklearn.neighbors import NearestNeighbors
model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
model_knn.fit(movie_features_df_matrix)
movie_features_df.shape

#selecting a movie whose similar movies would be shown
select_index = np.random.choice(movie_features_df.shape[0])
print(select_index)
distances, indices = model_knn.kneighbors(movie_features_df.iloc[select_index,:].values.reshape(1, -1), n_neighbors = 6)

indices.flatten()

for i in range(0, len(distances.flatten())):
    if i == 0:
        print('Recommendations for {0}:\n'.format(movie_features_df.index[select_index]))
    else:
        print('{0}: {1}, with distance of {2}:'.format(i, movie_features_df.index[indices.flatten()[i]], distances.flatten()[i]))

"""Hence the nearest movies to the given movie has been recommended by KNN Algorithm"""
